{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "pip install bio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "O5Df0mCcP_9z",
        "outputId": "e5d86b32-0745-435b-d025-ed6f46d09a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bio\n",
            "  Downloading bio-1.7.1-py3-none-any.whl.metadata (5.7 kB)\n",
            "Collecting biopython>=1.80 (from bio)\n",
            "  Downloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting gprofiler-official (from bio)\n",
            "  Downloading gprofiler_official-1.0.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting mygene (from bio)\n",
            "  Downloading mygene-3.2.2-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from bio) (2.2.2)\n",
            "Requirement already satisfied: pooch in /usr/local/lib/python3.10/dist-packages (from bio) (1.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bio) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bio) (4.66.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from biopython>=1.80->bio) (1.26.4)\n",
            "Collecting biothings-client>=0.2.6 (from mygene->bio)\n",
            "  Downloading biothings_client-0.3.1-py2.py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->bio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->bio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->bio) (2024.2)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch->bio) (4.3.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch->bio) (24.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bio) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bio) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bio) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bio) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->bio) (1.16.0)\n",
            "Downloading bio-1.7.1-py3-none-any.whl (280 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.0/281.0 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading biopython-1.84-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gprofiler_official-1.0.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading mygene-3.2.2-py2.py3-none-any.whl (5.4 kB)\n",
            "Downloading biothings_client-0.3.1-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: biopython, gprofiler-official, biothings-client, mygene, bio\n",
            "Successfully installed bio-1.7.1 biopython-1.84 biothings-client-0.3.1 gprofiler-official-1.0.0 mygene-3.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwoKDaD2TQc1",
        "outputId": "40ef55b1-d33f-441a-d3e3-38d4e5ae3d4b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from Bio import Entrez\n",
        "import re\n",
        "\n",
        "# Set your email here for NCBI Entrez\n",
        "Entrez.email = \"<your email>\"  # Replace with your actual email\n",
        "\n",
        "# Define a set of common stop words to exclude from scoring\n",
        "STOP_WORDS = {\"a\", \"and\", \"as\", \"at\", \"but\", \"by\", \"for\", \"from\", \"if\", \"in\", \"into\", \"of\", \"on\", \"or\", \"to\", \"the\"}\n",
        "\n",
        "def extract_words(title):\n",
        "    \"\"\"Extract all words from a title, excluding stop words.\"\"\"\n",
        "    words = re.findall(r'\\b\\w+\\b', title.lower())\n",
        "    filtered_words = [word for word in words if word not in STOP_WORDS]\n",
        "    return filtered_words\n",
        "\n",
        "def search_pubmed(title, max_results=200):\n",
        "    # Extract words from the title (case-insensitive) excluding stop words\n",
        "    words = extract_words(title)\n",
        "    lowercase_title = title.lower()  # Convert title to lowercase for comparison\n",
        "\n",
        "    if not words:\n",
        "        print(f\"No significant words found in title: '{title}'\")\n",
        "        return []\n",
        "\n",
        "    # Construct query string with \"OR\" to allow for broad matching based on any title word\n",
        "    word_query = \" OR \".join([f\"{word}[Title]\" for word in words])\n",
        "\n",
        "    # Search PubMed with sorting by relevance and a larger result count\n",
        "    handle = Entrez.esearch(db=\"pubmed\", term=word_query, retmax=max_results, sort=\"relevance\")\n",
        "    record = Entrez.read(handle)\n",
        "    handle.close()\n",
        "\n",
        "    # Get list of PubMed IDs\n",
        "    id_list = record[\"IdList\"]\n",
        "\n",
        "    # Fetch and rank titles for each PubMed ID\n",
        "    return fetch_and_rank_pubmed_titles(id_list, words, lowercase_title)\n",
        "\n",
        "def calculate_similarity_score(title, words):\n",
        "    \"\"\"Calculate the similarity score based on the number of matching words, case-insensitive.\"\"\"\n",
        "    score = sum(1 for word in words if re.search(rf'\\b{word}\\b', title, re.IGNORECASE))\n",
        "    return score\n",
        "\n",
        "def fetch_and_rank_pubmed_titles(id_list, words, lowercase_title, max_display=10):\n",
        "    # Fetch titles for a list of PubMed IDs\n",
        "    handle = Entrez.efetch(db=\"pubmed\", id=\",\".join(id_list), retmode=\"xml\")\n",
        "    records = Entrez.read(handle)\n",
        "    handle.close()\n",
        "\n",
        "    # Collect articles with scores\n",
        "    articles = []\n",
        "\n",
        "    # Extract title and PubMed ID for each result\n",
        "    for record in records[\"PubmedArticle\"]:\n",
        "        pubmed_id = record[\"MedlineCitation\"][\"PMID\"]\n",
        "        title = record[\"MedlineCitation\"][\"Article\"][\"ArticleTitle\"]\n",
        "\n",
        "        # Calculate similarity score\n",
        "        score = calculate_similarity_score(title.lower(), words)\n",
        "\n",
        "        # Append article information to list with score\n",
        "        articles.append({\n",
        "            \"PubMed ID\": pubmed_id,\n",
        "            \"Title\": title,\n",
        "            \"Score\": score\n",
        "        })\n",
        "\n",
        "    # Sort articles by similarity score in descending order and limit to top results\n",
        "    articles = sorted(articles, key=lambda x: x[\"Score\"], reverse=True)[:max_display]\n",
        "    return articles\n",
        "\n",
        "def process_titles_from_excel(input_file, output_file, title_column=\"Title\"):\n",
        "    # Load Excel file and read titles\n",
        "    df = pd.read_excel(input_file)\n",
        "    titles = df[title_column].dropna().tolist()  # Drop any empty cells in the title column\n",
        "\n",
        "    # Prepare list to store results\n",
        "    results = []\n",
        "\n",
        "    for input_title in titles:\n",
        "        print(f\"Processing title: {input_title}\")\n",
        "\n",
        "        # Get top 10 similar articles for each title\n",
        "        top_articles = search_pubmed(input_title)\n",
        "\n",
        "        # Store results with input title for each matched article\n",
        "        for article in top_articles:\n",
        "            results.append({\n",
        "                \"Input Title\": input_title,\n",
        "                \"PubMed ID\": article[\"PubMed ID\"],\n",
        "                \"Matched Title\": article[\"Title\"],\n",
        "                \"Score\": article[\"Score\"]\n",
        "            })\n",
        "\n",
        "        # Append an empty row after each title's results\n",
        "        results.append({\"Input Title\": \"\", \"PubMed ID\": \"\", \"Matched Title\": \"\", \"Score\": \"\"})\n",
        "\n",
        "    # Convert results to a DataFrame and save to Excel\n",
        "    output_df = pd.DataFrame(results)\n",
        "    output_df.to_excel(output_file, index=False)\n",
        "    print(f\"Results saved to {output_file}\")\n",
        "\n",
        "# Example usage\n",
        "input_file = \"<your input file>\"    # Path to the input Excel file containing titles\n",
        "output_file = \"<your output file>\"  # Path to save the output Excel file\n",
        "\n",
        "# Process titles and save results to an output file\n",
        "process_titles_from_excel(input_file, output_file)\n"
      ],
      "metadata": {
        "id": "8X8RHcH3iQdY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}